{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GasBotty Demonstration Notebook\n",
    "\n",
    "Authors: Anonymous Authors\n",
    "\n",
    "---\n",
    "\n",
    "In this work, we focus on the **accurate detection** and **reading** of gas prices, and their **contextual association** to gas grade and payment type (**Mult-Metric Extraction** *in the Wild*). In this notebook, we demonstrate the **GasBotty predictor**, a composite neural network model, by applying it to one of five dfferent sample images.\n",
    "\n",
    "### Setup Requirements\n",
    "\n",
    "This predictor builds off of the work of two existing frameworks, the [Keras RetinaNet](https://github.com/fizyr/keras-retinanet) and [DeepLabV3](https://github.com/leimao/DeepLab_v3) and has the following dependencies, listed within `requirements.txt`:\n",
    "* cython\n",
    "* keras-resnet\n",
    "* h5py\n",
    "* keras\n",
    "* matplotlib\n",
    "* numpy\n",
    "* opencv-python\n",
    "* pillow\n",
    "* progressbar2\n",
    "* tensorflow\n",
    "* torch\n",
    "* torchvision\n",
    "* scikit-learn\n",
    "* argparse\n",
    "* glob2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies & GasBotty Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "os.chdir('./GasBotty/')\n",
    "\n",
    "from GasBotty.gasbotty import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the Keras RetinaNet Depencies Locally\n",
    "\n",
    "This codebase contains a previously cloned copy of the Keras RetinaNet repository and need only be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Keras RetinaNet\n",
    "\n",
    "Note: The cloned Keras RetinaNet must be re-setup. Depending on your environment configuration, use either `python` or `python3`:\n",
    "\n",
    "`python3 setup.py build_ext --inplace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download each of the Released Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget https://github.com/anon93642/GasBotty/releases/download/v1.0/weights_101.pt -P ./weights/\n",
    "wget https://github.com/anon93642/GasBotty/releases/download/v1.0/resnet101_LABELSG1.h5 -P ./weights/\n",
    "wget https://github.com/anon93642/GasBotty/releases/download/v1.0/resnet101_DIGITSFINAL.h5 -P ./weights/\n",
    "wget https://github.com/anon93642/GasBotty/releases/download/v1.0/priceresnet50_csv_1all.h5 -P ./weights/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import each of pre-trained models\n",
    "\n",
    "GasBotty is a composite neural network incorporating four component models; after downloading them in the previous step, we load each here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_model, price_model, digit_model, label_model  = load_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load an Example Image\n",
    "\n",
    "By changing the index, an alternative image can be selected. Choose one of: `img_idx` \\\\( \\in [1,2,3,4,5] \\\\). The ground truth (`gt_file`) dataframe is loaded in the final step to compare against the predicted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx  = 1\n",
    "img_file = f'../example-images/example_{img_idx}.png'\n",
    "gt_file  = f'../example-images/example_{img_idx}.csv' \n",
    "image    = cv2.imread(img_file)\n",
    "plt.imshow(cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: From the Image, Predict the Sign-Level Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = get_mask(image, sign_model)\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: From the Predicted Sign-Level Mask, Extract  the Border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border = get_border(mask)\n",
    "plt.imshow(border)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Using the Extracted Border, Detect the Hough Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df, line_image = get_lines(border, image.copy())\n",
    "plt.imshow(cv2.cvtColor(line_image.copy(), cv2.COLOR_BGR2RGB))\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: From the Detected Hough lines, Obtain the Points of Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_df, intersection_image = get_intersections(line_df, line_image)\n",
    "plt.imshow(cv2.cvtColor(intersection_image.copy(), cv2.COLOR_BGR2RGB))\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: From the Points of Intersection, Obtain the Sign-Level Corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pts, corners_image = get_corners(intersection_df, intersection_image)\n",
    "plt.imshow(cv2.cvtColor(corners_image.copy(), cv2.COLOR_BGR2RGB))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Keystone Correct the Sign using Four Corners\n",
    "\n",
    "This steep generates a sign-level, perspective-corrected image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keystone_image = get_KS(src_pts, image.copy())\n",
    "plt.imshow(cv2.cvtColor(keystone_image.copy(), cv2.COLOR_BGR2RGB))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Using the Sign-Level Image, Extract all Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_prices, price_image = price_level(keystone_image.copy(), price_model)\n",
    "plt.imshow(cv2.cvtColor(price_image.copy(), cv2.COLOR_BGR2RGB))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Using the Sign-Level Image, Extract all Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_labels, label_image = label_level(keystone_image.copy(), label_model, price_image)\n",
    "plt.imshow(cv2.cvtColor(label_image.copy(), cv2.COLOR_BGR2RGB))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Using all Extracted Price-Level Images, Detect all Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = []\n",
    "for price in where_prices:\n",
    "    current_price, price_image = read_digits(keystone_image.copy()[price[1]:price[3], price[0]:price[2]] , digit_model )\n",
    "    prices.append(( price[0], price[1], price[2], price[3], current_price))        \n",
    "    plt.imshow(cv2.cvtColor(price_image.copy(), cv2.COLOR_BGR2RGB))\n",
    "    plt.title(str(current_price))\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Using all Extracted Prices & Labels, Associate & Generate Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df , associate_image = associate(prices, where_labels, label_image)\n",
    "plt.imshow(cv2.cvtColor(associate_image.copy(), cv2.COLOR_BGR2RGB))\n",
    "plt.show() \n",
    "print(f'Complete Predicted Dataframe:\\n{df}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Step: Evaluate Performance with Ground Truth Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groundtruth = pd.read_csv(gt_file)\n",
    "df_groundtruth['Price'] = df_groundtruth['Price'].round(3)\n",
    "print(f'All-or-Nothing Accuracy (ANA): {ANA(df, df_groundtruth)}\\n\\nPredicted:\\n{df}\\n\\nGround Truth:\\n{df_groundtruth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thats all Folks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
